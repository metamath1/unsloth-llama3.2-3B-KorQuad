{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-29 22:28:54--  https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_train.json\n",
      "raw.githubusercontent.com (raw.githubusercontent.com) 해석 중... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "다음으로 연결 중: raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 38527475 (37M) [text/plain]\n",
      "저장 위치: ‘KorQuAD_v1.0_train.json’\n",
      "\n",
      "KorQuAD_v1.0_train. 100%[===================>]  36.74M  9.93MB/s    / 3.7s     \n",
      "\n",
      "2024-09-29 22:29:01 (10.0 MB/s) - ‘KorQuAD_v1.0_train.json’ 저장함 [38527475/38527475]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_train.json -O KorQuAD_v1.0_train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-29 22:29:02--  https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_dev.json\n",
      "raw.githubusercontent.com (raw.githubusercontent.com) 해석 중... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "다음으로 연결 중: raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 3881058 (3.7M) [text/plain]\n",
      "저장 위치: ‘KorQuAD_v1.0_dev.json’\n",
      "\n",
      "KorQuAD_v1.0_dev.js 100%[===================>]   3.70M  10.9MB/s    / 0.3s     \n",
      "\n",
      "2024-09-29 22:29:04 (10.9 MB/s) - ‘KorQuAD_v1.0_dev.json’ 저장함 [3881058/3881058]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_dev.json -O KorQuAD_v1.0_dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('KorQuAD_v1.0_dev.json', 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "with open('KorQuAD_v1.0_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def korquad_to_dataframe(data):\n",
    "    rows = []\n",
    "    for paragraph in data['data']:\n",
    "        paragraph_title = paragraph['title']\n",
    "\n",
    "        for qa in paragraph['paragraphs']:\n",
    "            context = qa['context']\n",
    "\n",
    "            for question in qa['qas']:\n",
    "                q = question['question']\n",
    "                qa_id = question['id']\n",
    "\n",
    "                for answer in question['answers']:\n",
    "                    a = answer['text']\n",
    "                    rows.append({\n",
    "                        'question': q,\n",
    "                        'answer': a,\n",
    "                        'qa_id': qa_id,\n",
    "                        'context': context,\n",
    "                        'paragraph_title': paragraph_title\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>context</th>\n",
       "      <th>paragraph_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?</td>\n",
       "      <td>1989년 2월 15일</td>\n",
       "      <td>6548850-0-0</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989년 6월 30일 평양축전에 대표로 파견 된 인물은?</td>\n",
       "      <td>임수경</td>\n",
       "      <td>6548850-0-1</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?</td>\n",
       "      <td>1989년</td>\n",
       "      <td>6548853-0-0</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>임종석을 검거한 장소는 경희대 내 어디인가?</td>\n",
       "      <td>학생회관 건물 계단</td>\n",
       "      <td>6548853-0-1</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임종석이 조사를 받은 뒤 인계된 곳은 어딘가?</td>\n",
       "      <td>서울지방경찰청 공안분실</td>\n",
       "      <td>6548853-0-2</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                question        answer        qa_id  \\\n",
       "0  임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?  1989년 2월 15일  6548850-0-0   \n",
       "1       1989년 6월 30일 평양축전에 대표로 파견 된 인물은?           임수경  6548850-0-1   \n",
       "2  임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?         1989년  6548853-0-0   \n",
       "3               임종석을 검거한 장소는 경희대 내 어디인가?    학생회관 건물 계단  6548853-0-1   \n",
       "4              임종석이 조사를 받은 뒤 인계된 곳은 어딘가?  서울지방경찰청 공안분실  6548853-0-2   \n",
       "\n",
       "                                             context paragraph_title  \n",
       "0  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...             임종석  \n",
       "1  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...             임종석  \n",
       "2  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...             임종석  \n",
       "3  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...             임종석  \n",
       "4  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...             임종석  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = korquad_to_dataframe(dev_data)\n",
    "print(df_dev.shape)\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60407, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>context</th>\n",
       "      <th>paragraph_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?</td>\n",
       "      <td>교향곡</td>\n",
       "      <td>6566495-0-0</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?</td>\n",
       "      <td>1악장</td>\n",
       "      <td>6566495-0-1</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?</td>\n",
       "      <td>베토벤의 교향곡 9번</td>\n",
       "      <td>6566495-0-2</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?</td>\n",
       "      <td>파우스트</td>\n",
       "      <td>6566518-0-0</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?</td>\n",
       "      <td>합창교향곡</td>\n",
       "      <td>6566518-0-1</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question       answer        qa_id  \\\n",
       "0     바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?          교향곡  6566495-0-0   \n",
       "1      바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?          1악장  6566495-0-1   \n",
       "2  바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?  베토벤의 교향곡 9번  6566495-0-2   \n",
       "3     1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?         파우스트  6566518-0-0   \n",
       "4   파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?        합창교향곡  6566518-0-1   \n",
       "\n",
       "                                             context paragraph_title  \n",
       "0  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...         파우스트_서곡  \n",
       "1  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...         파우스트_서곡  \n",
       "2  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...         파우스트_서곡  \n",
       "3  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...         파우스트_서곡  \n",
       "4  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...         파우스트_서곡  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = korquad_to_dataframe(train_data)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question  context  answer\n",
       "False     False    False     66181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[['question', 'context', 'answer']]\n",
    "df_dev = df_dev[['question', 'context', 'answer']]\n",
    "\n",
    "df = pd.concat([df_train, df_dev], axis=0).reset_index(drop=True)\n",
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.9.post3: Fast Llama patching. Transformers = 4.45.1.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.688 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "def format_example(row):\n",
    "    prompt = f\"\"\"{row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{row[\"context\"]}\n",
    "###\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]}\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df.apply(format_example, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>교향곡</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>1악장</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>베토벤의 교향곡 9번</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>합창교향곡</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "0     바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?   \n",
       "1      바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?   \n",
       "2  바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?   \n",
       "3     1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?   \n",
       "4   파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?   \n",
       "\n",
       "                                             context       answer  \\\n",
       "0  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...          교향곡   \n",
       "1  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...          1악장   \n",
       "2  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...  베토벤의 교향곡 9번   \n",
       "3  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...         파우스트   \n",
       "4  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...        합창교향곡   \n",
       "\n",
       "                                                text  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "교향곡<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# system 프롬프트에 \n",
    "# Cutting Knowledge Date: December 2023\n",
    "# Today Date: 26 July 2024 가 추가되어 llama 3.1 프롬프트 탬플릿임을 확인\n",
    "\n",
    "print(df.loc[0,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(row):\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row['text'],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False\n",
    "        )[\"input_ids\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.5 s, sys: 0 ns, total: 29.5 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>교향곡</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>1악장</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>베토벤의 교향곡 9번</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>합창교향곡</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "0     바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?   \n",
       "1      바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?   \n",
       "2  바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?   \n",
       "3     1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?   \n",
       "4   파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?   \n",
       "\n",
       "                                             context       answer  \\\n",
       "0  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...          교향곡   \n",
       "1  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...          1악장   \n",
       "2  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...  베토벤의 교향곡 9번   \n",
       "3  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...         파우스트   \n",
       "4  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...        합창교향곡   \n",
       "\n",
       "                                                text  token_count  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...          511  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...          510  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...          520  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...          509  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...          514  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['token_count'], ec='k', bins=30, weights=np.ones(len(df['token_count'])) / len(df['token_count']) )\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57139, 66181, 0.8633746845771445)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['token_count'] < 512]), len(df), len(df[df['token_count'] < 512]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# def seed_everything(seed: int):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "\n",
    "# seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 5)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 길이로 적당히 학습 샘플 서브샘플링 \n",
    "df_sampled = df[df[\"token_count\"] < 512]\n",
    "df_sampled = df_sampled.sample(6000, random_state=SEED)\n",
    "df_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, temp = train_test_split(df_sampled, test_size=0.2, random_state=SEED)\n",
    "val, test = train_test_split(temp, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data ratio:0.8, 4800\n",
      "Valid data ratio:0.16, 960\n",
      "Test data ratio:0.04, 240\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data ratio:{len(train) / len(df_sampled)}, {len(train)}\")\n",
    "print(f\"Valid data ratio:{len(val) / len(df_sampled)}, {len(val)}\")\n",
    "print(f\"Test data ratio:{len(test) / len(df_sampled)}, {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(n=4000, random_state=SEED).to_json(\"train.json\", orient=\"records\", lines=True)\n",
    "val.sample(n=500, random_state=SEED).to_json(\"val.json\", orient=\"records\", lines=True)\n",
    "test.sample(n=100, random_state=SEED).to_json(\"test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5665265cbd43a8afed5aafefd1f4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19324b4f5a724650901b354956bb51eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d077affbdc4c04a40c46d9abe09b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"train.json\",\n",
    "        \"validation\": \"val.json\",\n",
    "        \"test\": \"test.json\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = f\"\"\"{data_row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{data_row[\"context\"]}\n",
    "###\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False,\n",
    "        # 프롬프트 끝에\n",
    "        # <|start_header_id|>assistant<|end_header_id|>\n",
    "        # 를 붙이게 됨\n",
    "        add_generation_prompt=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 셋에 대해서 학습전 출력을 확인\n",
    "\n",
    "def inf_test_one_sample(example):\n",
    "    prompt = create_test_prompt(example)\n",
    "    print(\"\\nPROMPT\\n\", prompt.strip())\n",
    "    \n",
    "    inputs = torch.tensor([tokenizer(prompt)['input_ids']]).to('cuda')\n",
    "\n",
    "    outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
    "                         temperature = 1.5, min_p = 0.1)\n",
    "\n",
    "    print(\"\\nANS\\n\", example['answer'])\n",
    "    print(\"\\nPRED\\n\", tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip())\n",
    "\n",
    "    return example['answer'], tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip()\n",
    "\n",
    "FastLanguageModel.for_inference(model);\n",
    "\n",
    "untrained = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "니노이 아키노 국제공항이 처음으로 국내선을 운영한 시기는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "터미널 공식적으로 선택한 국내선으로 2008년 7월 22일(처음에는 세부 퍼시픽만, 그 필리핀 항공의 자회사 항공 필리핀과 PAL 익스프레스)에서, 세부 퍼시픽과 함께 문을 열었다. 국제선은 8월 1일 2008년이다. PAL에서 제외한 모든 국제 작전에서 사용하는 3번 터미널에서 미래에 운영하고, 원래에서 움직이겠다는 제안을 위한 것이다.그의 처음 2년 동안 2010년, 하지만 국내 항공사 세부 퍼시픽과 에어 필 익스프레스(그 항공 필리핀 그리고 그들은 PAL 익스프레스)의 4분기 남아 있는 유일한 세입자들이다. 작동 국제선의 대부분은 터미널 1부터 전 일본 항공은 첫 외국계 항공사 터미널 3은 2월 27일에 운영되는 것을 제외하고 운영되고 있다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 2008년 7월 22일\n",
      "\n",
      "PRED\n",
      " 니노이 아키노 국제공항이 처음으로 domestically 선을 운영한 시기는 2008년 7월 22일에, 2008년 8월 1日に 국제선을 운영하기 시작했다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "주한일본공사의 스즈키는 누구를 카라와 함께 일본의 신한류를 이끄는 그룹이라 언급했는가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "소녀시대는 한류를 이끄는 주역으로도 인정 받고 있다. 주한일본공사 스즈키 히로시는 이들을 카라와 함께 일본의 신한류를 이끄는 그룹이라고 말했으며, 《경향신문》에서는 \"소녀시대는 대중문화의 아이콘, 아시아를 넘어 유럽까지 진출한 한류의 선두주자가 됐다\"라며 \"한류 열풍 이끄는 아시아 최고 걸그룹\"이라고 말했다. 브라질의 연예 프로그램인 ‘Leitura Dinamica’는 브라질의 k-pop 열풍을 소개하며 소녀시대를 예로 들며, “신곡 ‘훗’은 브라질 뿐 아니라 세계 유명 DJ들에게도 큰 인기다. 그야말로 소녀시대가 쏜 화살이 아시아를 넘어 세계로 날아가고 있는 셈”이라고 호평했다. 또 아리랑TV가 연 ‘K POP - 따라하기’에서 가장 많이 패러디된 가수는 소녀시대였으며, 인도네시아 팬들은 소녀시대의 라이브 공연을 자국에서 해 달라고 서명 운동을 벌이기도 했다. 소시지룩, 마린룩 등 패션은 대한민국에서 인기를 끌었으며, 특히 후루야 마사유키는 그들이 일본 젊은 여성들의 패션 아이콘이라고 말했다. 또한 일본 영어 교과서에 “전 세계에서 인기를 얻고 있는 K-pop 스타들”이라는 제목으로 K-pop의 대표로 소녀시대를 소개하며 사진이 삽입되었다. KIIS의 음악 감독인 줄리 필랏 (Julie Pilat)은 2012년 주목할 그룹으로 뽑기도 했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 소녀시대\n",
      "\n",
      "PRED\n",
      " 소녀시대가 주한일본공사의 스즈키 히로시는 카라와 함께 일본의 신한류를 이끄는 그룹이라고 언급했었습니다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "변희재가 운영했던 인터넷사이트는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2003년 2월 12일 KBS 신임 사장 인선 관련 공청회에 참여했을 때는 코드 인사, 낙하산 인사가 아닌 방송을 잘 아는 인물이 선임되어야 한다는 견해를 피력하였다. 당시 인터넷사이트 '서프라이즈' 운영자였던 변희재는 \"KBS 사장은 늘 '지사풍'의 언론인이 와야 한다는 강박관념이 잘못된 인선을 부른다\"며 \"지금 이 자리에서 언급되고 있는 언론인 정모씨나 강모 교수가 사장으로 선임이 된다고 해도 보도국과 교양프로만 챙기는 사장이 될 것이다. 언론인 중 방송을 아는 인물이 와서 현재 문제가 많은 오락프로 등도 개선해야 할 것\"이라고 밝혔다. 그는 또 \"시청률에 대한 부담이 상대적으로 덜한 KBS는 이제 '공정성'이라는 말보다는 '실험성'을 강조해야 할 것\"이라고 강조했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 서프라이즈\n",
      "\n",
      "PRED\n",
      " 변희재는 서프라이즈(이론적意义에서 보도용의로 보는가? ) 운영자 였다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][2])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "어디서 개복치를 식용으로 파는것을 금지하는가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "한국과 일본, 대만에서는 식용으로 먹기도 하는데 몸체의 대부분을 먹을 수 있다. 맛과 모양은 기름기가 많아 하얗고 뽀얀 편이라 참치 흰살과 비슷하다. 회로 먹기도 하는데 비린내가 안 나는 편이나 기름이 소화가 잘 안 돼, 많이 먹으면 설사를 유발하기도 한다. 등 쪽에서 나오는 흰색의 창자는 중국에선 용창이라는 이름으로 별미로 여겨지기도 하며 지느러미를 몸통의 살보다 별미로 취급한다. 껍질은 삶으면 흐물흐물해지는데, 이것을 우뭇가사리와 비슷하게 만들어 먹을 수 있다. 어떤 지역에서는 약재로 쓰이기도 한다. 대한민국에서는 포항 지역에서 개복치를 대소사에 쓰이는 별미 재료로 사용해 왔다. 구체적으로 껍질은 수육, 뱃살은 회무침용, 머리뼈와 머릿살은 찜 요리 재료로 사용한다. 근육 부분은 갈아서 부산 어묵에 들어가는 경우도 있다. 한편 유럽 연합에서는 개복치를 식용으로 파는 것이 금지되어 있다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 유럽 연합\n",
      "\n",
      "PRED\n",
      " 유럽 연합<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][3])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2008년 7월 22일',\n",
       "  '니노이 아키노 국제공항이 처음으로 domestically 선을 운영한 시기는 2008년 7월 22일에, 2008년 8월 1日に 국제선을 운영하기 시작했다.<|eot_id|>'),\n",
       " ('소녀시대',\n",
       "  '소녀시대가 주한일본공사의 스즈키 히로시는 카라와 함께 일본의 신한류를 이끄는 그룹이라고 언급했었습니다.<|eot_id|>'),\n",
       " ('서프라이즈', '변희재는 서프라이즈(이론적意义에서 보도용의로 보는가? ) 운영자 였다.<|eot_id|>'),\n",
       " ('유럽 연합', '유럽 연합<|eot_id|>')]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_training(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dad8c5a14a547bc95c79ce311fc7def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e465a6cbe694f8d9eaeab8eb8bfb2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 1e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.2,\n",
    "        save_steps=0.2,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a26a1d0cb74df7bacc48284064d625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6ff6ab779148058ebe55b3802dd86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습을 위한 로스의 계산은 입력 프롬프트 제외하고 출력 부분만 해당되므로\n",
    "# 입력과 출력 부분을 구분하기 위해 구분자를 세팅\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "아이폰을 도입한 이후 불화가 일기 시작한 두 기업은 어디인가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "아이폰을 도입한 이후로 KT와 삼성전자간의 불화가 일기 시작하였다. 아이폰 출시로 인해 스마트폰 부분에서 삼성은 매출과 이미지에 타격을 입었으며, 삼성의 대표적인 스마트폰인 옴니아2의 만족도 조사와, 스마트폰 선호도 조사에서 삼성은 애플에 크게 떨어져 굴욕을 맛보아야 했다. 삼성은 그에 따라 KT에 대한 불편한 심기를 감추지 않았으며, 이후 삼성의 각종 스마트폰 출시에서 KT가 제외되거나, 보조금 지급 대상에서 제외되거나, 업그레이드를 해주지 않거나, 심지어 '쇼옴니아' 명칭 조차 사용할 수 없게 하는 등 KT에 대한 삼성의 차별이 시작되었다. KT는 아이폰을 출시함으로 인해 큰 영향력을 행사하는 계기가 되었으나, 대한민국 최대 휴대 전화 제조사인 삼성과의 불화로 인해 대한민국의 스마트폰을 원활하게 확보하기가 어렵게 되는 위기에 처하기도 하였다. 이후 SK텔레콤을 통해서 출시된 삼성의 스마트폰 '갤럭시' 시리즈도 몇개월 이상 지나서 KT에서 출시되었으며 삼성의 '바다' 운영 체제를 탑재한 '웨이브2'는 KT에서 아예 출시 할 계획이 없는 것으로 알려졌다. 이와는 별개로 웨이브3는 KT에 정상적으로 출시되었다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "KT와 삼성전자<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print( tokenizer.decode(trainer.train_dataset[5][\"input_ids\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "\n",
      "KT와 삼성전자<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# trainer.train_dataset의 labels에는 instruction에 해당하는 입력부분은 모두 -100으로\n",
    "# 마스킹됨을 확인\n",
    "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
    "print( tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 4,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 500\n",
      " \"-____-\"     Number of trainable parameters = 24,313,856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161dfc47f2694808b3aeea590be30426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7036, 'grad_norm': 9.051045417785645, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
      "{'loss': 1.523, 'grad_norm': 7.179967880249023, 'learning_rate': 4e-05, 'epoch': 0.0}\n",
      "{'loss': 1.8045, 'grad_norm': 5.704689979553223, 'learning_rate': 6e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8835, 'grad_norm': 7.906423091888428, 'learning_rate': 8e-05, 'epoch': 0.01}\n",
      "{'loss': 1.5441, 'grad_norm': 8.5809965133667, 'learning_rate': 0.0001, 'epoch': 0.01}\n",
      "{'loss': 1.3954, 'grad_norm': 10.389257431030273, 'learning_rate': 9.97979797979798e-05, 'epoch': 0.01}\n",
      "{'loss': 0.4933, 'grad_norm': 4.006084442138672, 'learning_rate': 9.95959595959596e-05, 'epoch': 0.01}\n",
      "{'loss': 0.5702, 'grad_norm': 2.750704526901245, 'learning_rate': 9.939393939393939e-05, 'epoch': 0.02}\n",
      "{'loss': 0.5063, 'grad_norm': 2.4367377758026123, 'learning_rate': 9.919191919191919e-05, 'epoch': 0.02}\n",
      "{'loss': 0.3837, 'grad_norm': 3.509213447570801, 'learning_rate': 9.8989898989899e-05, 'epoch': 0.02}\n",
      "{'loss': 0.7336, 'grad_norm': 4.158539772033691, 'learning_rate': 9.87878787878788e-05, 'epoch': 0.02}\n",
      "{'loss': 0.3073, 'grad_norm': 2.146646738052368, 'learning_rate': 9.85858585858586e-05, 'epoch': 0.02}\n",
      "{'loss': 0.2309, 'grad_norm': 1.582779884338379, 'learning_rate': 9.838383838383838e-05, 'epoch': 0.03}\n",
      "{'loss': 0.4186, 'grad_norm': 2.710871934890747, 'learning_rate': 9.818181818181818e-05, 'epoch': 0.03}\n",
      "{'loss': 0.2943, 'grad_norm': 2.8295745849609375, 'learning_rate': 9.797979797979798e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1717, 'grad_norm': 4.102239608764648, 'learning_rate': 9.777777777777778e-05, 'epoch': 0.03}\n",
      "{'loss': 0.3788, 'grad_norm': 2.845398426055908, 'learning_rate': 9.757575757575758e-05, 'epoch': 0.03}\n",
      "{'loss': 0.4509, 'grad_norm': 1.652683138847351, 'learning_rate': 9.737373737373738e-05, 'epoch': 0.04}\n",
      "{'loss': 0.339, 'grad_norm': 1.2526427507400513, 'learning_rate': 9.717171717171718e-05, 'epoch': 0.04}\n",
      "{'loss': 0.278, 'grad_norm': 2.842186212539673, 'learning_rate': 9.696969696969698e-05, 'epoch': 0.04}\n",
      "{'loss': 0.2779, 'grad_norm': 2.465791940689087, 'learning_rate': 9.676767676767677e-05, 'epoch': 0.04}\n",
      "{'loss': 0.4382, 'grad_norm': 2.8189971446990967, 'learning_rate': 9.656565656565657e-05, 'epoch': 0.04}\n",
      "{'loss': 0.353, 'grad_norm': 2.4813120365142822, 'learning_rate': 9.636363636363637e-05, 'epoch': 0.05}\n",
      "{'loss': 0.2993, 'grad_norm': 3.567899703979492, 'learning_rate': 9.616161616161616e-05, 'epoch': 0.05}\n",
      "{'loss': 0.3606, 'grad_norm': 2.7154347896575928, 'learning_rate': 9.595959595959596e-05, 'epoch': 0.05}\n",
      "{'loss': 0.9006, 'grad_norm': 5.072595596313477, 'learning_rate': 9.575757575757576e-05, 'epoch': 0.05}\n",
      "{'loss': 0.4907, 'grad_norm': 3.070021867752075, 'learning_rate': 9.555555555555557e-05, 'epoch': 0.05}\n",
      "{'loss': 0.4474, 'grad_norm': 2.8543596267700195, 'learning_rate': 9.535353535353537e-05, 'epoch': 0.06}\n",
      "{'loss': 0.2198, 'grad_norm': 1.018824815750122, 'learning_rate': 9.515151515151515e-05, 'epoch': 0.06}\n",
      "{'loss': 0.2219, 'grad_norm': 2.0878829956054688, 'learning_rate': 9.494949494949495e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0521, 'grad_norm': 0.6802138090133667, 'learning_rate': 9.474747474747475e-05, 'epoch': 0.06}\n",
      "{'loss': 0.3491, 'grad_norm': 2.4381847381591797, 'learning_rate': 9.454545454545455e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4973, 'grad_norm': 4.04633092880249, 'learning_rate': 9.434343434343435e-05, 'epoch': 0.07}\n",
      "{'loss': 0.278, 'grad_norm': 3.065171241760254, 'learning_rate': 9.414141414141415e-05, 'epoch': 0.07}\n",
      "{'loss': 0.183, 'grad_norm': 2.029571056365967, 'learning_rate': 9.393939393939395e-05, 'epoch': 0.07}\n",
      "{'loss': 0.2622, 'grad_norm': 2.7520952224731445, 'learning_rate': 9.373737373737375e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0728, 'grad_norm': 0.7763343453407288, 'learning_rate': 9.353535353535354e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1484, 'grad_norm': 1.768947720527649, 'learning_rate': 9.333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 0.4087, 'grad_norm': 4.2838850021362305, 'learning_rate': 9.313131313131314e-05, 'epoch': 0.08}\n",
      "{'loss': 0.5394, 'grad_norm': 4.025154113769531, 'learning_rate': 9.292929292929293e-05, 'epoch': 0.08}\n",
      "{'loss': 0.2448, 'grad_norm': 5.421754360198975, 'learning_rate': 9.272727272727273e-05, 'epoch': 0.08}\n",
      "{'loss': 0.2709, 'grad_norm': 3.5817065238952637, 'learning_rate': 9.252525252525253e-05, 'epoch': 0.08}\n",
      "{'loss': 0.2698, 'grad_norm': 4.724947452545166, 'learning_rate': 9.232323232323232e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7445, 'grad_norm': 3.390611410140991, 'learning_rate': 9.212121212121214e-05, 'epoch': 0.09}\n",
      "{'loss': 0.053, 'grad_norm': 0.32235658168792725, 'learning_rate': 9.191919191919192e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1763, 'grad_norm': 1.554938554763794, 'learning_rate': 9.171717171717172e-05, 'epoch': 0.09}\n",
      "{'loss': 0.3699, 'grad_norm': 3.2928578853607178, 'learning_rate': 9.151515151515152e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6697, 'grad_norm': 3.8543148040771484, 'learning_rate': 9.131313131313132e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0878, 'grad_norm': 2.643181800842285, 'learning_rate': 9.111111111111112e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0364, 'grad_norm': 0.5814037919044495, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0568, 'grad_norm': 1.6959882974624634, 'learning_rate': 9.07070707070707e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1153, 'grad_norm': 1.7444705963134766, 'learning_rate': 9.050505050505052e-05, 'epoch': 0.1}\n",
      "{'loss': 0.2748, 'grad_norm': 2.0630943775177, 'learning_rate': 9.030303030303031e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0466, 'grad_norm': 0.47280749678611755, 'learning_rate': 9.010101010101011e-05, 'epoch': 0.11}\n",
      "{'loss': 0.2569, 'grad_norm': 1.3771916627883911, 'learning_rate': 8.98989898989899e-05, 'epoch': 0.11}\n",
      "{'loss': 0.2218, 'grad_norm': 3.1388349533081055, 'learning_rate': 8.96969696969697e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0482, 'grad_norm': 0.4291129410266876, 'learning_rate': 8.94949494949495e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1969, 'grad_norm': 2.0696864128112793, 'learning_rate': 8.92929292929293e-05, 'epoch': 0.12}\n",
      "{'loss': 0.454, 'grad_norm': 3.4115684032440186, 'learning_rate': 8.90909090909091e-05, 'epoch': 0.12}\n",
      "{'loss': 0.282, 'grad_norm': 4.5914764404296875, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0858, 'grad_norm': 1.1058404445648193, 'learning_rate': 8.868686868686869e-05, 'epoch': 0.12}\n",
      "{'loss': 0.4837, 'grad_norm': 4.00076961517334, 'learning_rate': 8.848484848484849e-05, 'epoch': 0.12}\n",
      "{'loss': 0.4203, 'grad_norm': 1.7066197395324707, 'learning_rate': 8.828282828282829e-05, 'epoch': 0.13}\n",
      "{'loss': 0.2766, 'grad_norm': 4.725783824920654, 'learning_rate': 8.808080808080809e-05, 'epoch': 0.13}\n",
      "{'loss': 0.225, 'grad_norm': 2.5210421085357666, 'learning_rate': 8.787878787878789e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0376, 'grad_norm': 0.9452601671218872, 'learning_rate': 8.767676767676767e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1929, 'grad_norm': 2.4264867305755615, 'learning_rate': 8.747474747474747e-05, 'epoch': 0.13}\n",
      "{'loss': 0.2144, 'grad_norm': 4.366684913635254, 'learning_rate': 8.727272727272727e-05, 'epoch': 0.14}\n",
      "{'loss': 0.3205, 'grad_norm': 6.591679096221924, 'learning_rate': 8.707070707070707e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1119, 'grad_norm': 3.626723289489746, 'learning_rate': 8.686868686868688e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1828, 'grad_norm': 2.306269407272339, 'learning_rate': 8.666666666666667e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4557, 'grad_norm': 2.1522648334503174, 'learning_rate': 8.646464646464647e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1503, 'grad_norm': 1.2153209447860718, 'learning_rate': 8.626262626262627e-05, 'epoch': 0.15}\n",
      "{'loss': 0.2019, 'grad_norm': 2.715137004852295, 'learning_rate': 8.606060606060606e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0488, 'grad_norm': 0.696492612361908, 'learning_rate': 8.585858585858586e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1431, 'grad_norm': 1.0779542922973633, 'learning_rate': 8.565656565656566e-05, 'epoch': 0.15}\n",
      "{'loss': 0.3307, 'grad_norm': 1.7599602937698364, 'learning_rate': 8.545454545454545e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1885, 'grad_norm': 1.8450305461883545, 'learning_rate': 8.525252525252526e-05, 'epoch': 0.16}\n",
      "{'loss': 0.187, 'grad_norm': 1.880353331565857, 'learning_rate': 8.505050505050506e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1825, 'grad_norm': 4.654876232147217, 'learning_rate': 8.484848484848486e-05, 'epoch': 0.16}\n",
      "{'loss': 0.4168, 'grad_norm': 2.6512858867645264, 'learning_rate': 8.464646464646466e-05, 'epoch': 0.16}\n",
      "{'loss': 0.4455, 'grad_norm': 4.572525978088379, 'learning_rate': 8.444444444444444e-05, 'epoch': 0.16}\n",
      "{'loss': 0.5434, 'grad_norm': 3.0402944087982178, 'learning_rate': 8.424242424242424e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0271, 'grad_norm': 1.0660755634307861, 'learning_rate': 8.404040404040404e-05, 'epoch': 0.17}\n",
      "{'loss': 0.3633, 'grad_norm': 1.3885208368301392, 'learning_rate': 8.383838383838384e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0726, 'grad_norm': 1.650164246559143, 'learning_rate': 8.363636363636364e-05, 'epoch': 0.17}\n",
      "{'loss': 0.021, 'grad_norm': 0.17552968859672546, 'learning_rate': 8.343434343434344e-05, 'epoch': 0.17}\n",
      "{'loss': 0.041, 'grad_norm': 0.5957064032554626, 'learning_rate': 8.323232323232324e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3206, 'grad_norm': 3.3027472496032715, 'learning_rate': 8.303030303030304e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0496, 'grad_norm': 1.0469307899475098, 'learning_rate': 8.282828282828283e-05, 'epoch': 0.18}\n",
      "{'loss': 0.4895, 'grad_norm': 14.788640022277832, 'learning_rate': 8.262626262626263e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1257, 'grad_norm': 1.3928560018539429, 'learning_rate': 8.242424242424243e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1478, 'grad_norm': 3.65592885017395, 'learning_rate': 8.222222222222222e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1529, 'grad_norm': 7.908723831176758, 'learning_rate': 8.202020202020202e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1972, 'grad_norm': 3.002326488494873, 'learning_rate': 8.181818181818183e-05, 'epoch': 0.19}\n",
      "{'loss': 0.2309, 'grad_norm': 4.775179386138916, 'learning_rate': 8.161616161616163e-05, 'epoch': 0.19}\n",
      "{'loss': 0.2057, 'grad_norm': 4.259324550628662, 'learning_rate': 8.141414141414141e-05, 'epoch': 0.19}\n",
      "{'loss': 0.3501, 'grad_norm': 3.153540849685669, 'learning_rate': 8.121212121212121e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1531, 'grad_norm': 0.6973878145217896, 'learning_rate': 8.101010101010101e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3275, 'grad_norm': 5.529916763305664, 'learning_rate': 8.080808080808081e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b136319eae3846c186c4552f802ff92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2724214494228363, 'eval_runtime': 31.6286, 'eval_samples_per_second': 15.808, 'eval_steps_per_second': 1.992, 'epoch': 0.2}\n",
      "{'loss': 0.2842, 'grad_norm': 13.598481178283691, 'learning_rate': 8.060606060606061e-05, 'epoch': 0.2}\n",
      "{'loss': 0.4501, 'grad_norm': 3.662079095840454, 'learning_rate': 8.040404040404041e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1179, 'grad_norm': 1.589817762374878, 'learning_rate': 8.02020202020202e-05, 'epoch': 0.21}\n",
      "{'loss': 0.125, 'grad_norm': 2.702413320541382, 'learning_rate': 8e-05, 'epoch': 0.21}\n",
      "{'loss': 0.4187, 'grad_norm': 2.935258150100708, 'learning_rate': 7.97979797979798e-05, 'epoch': 0.21}\n",
      "{'loss': 0.5465, 'grad_norm': 3.196913957595825, 'learning_rate': 7.95959595959596e-05, 'epoch': 0.21}\n",
      "{'loss': 0.1124, 'grad_norm': 2.75850510597229, 'learning_rate': 7.93939393939394e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0944, 'grad_norm': 0.9826244115829468, 'learning_rate': 7.919191919191919e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0516, 'grad_norm': 1.33893620967865, 'learning_rate': 7.898989898989899e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1235, 'grad_norm': 1.6088846921920776, 'learning_rate': 7.878787878787879e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1433, 'grad_norm': 3.600128173828125, 'learning_rate': 7.858585858585859e-05, 'epoch': 0.22}\n",
      "{'loss': 0.2417, 'grad_norm': 3.04272198677063, 'learning_rate': 7.83838383838384e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1523, 'grad_norm': 1.497880220413208, 'learning_rate': 7.818181818181818e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0919, 'grad_norm': 2.7053704261779785, 'learning_rate': 7.797979797979798e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3204, 'grad_norm': 3.1910486221313477, 'learning_rate': 7.777777777777778e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3859, 'grad_norm': 2.489480972290039, 'learning_rate': 7.757575757575758e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1203, 'grad_norm': 3.7686398029327393, 'learning_rate': 7.737373737373738e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0536, 'grad_norm': 0.6726845502853394, 'learning_rate': 7.717171717171718e-05, 'epoch': 0.24}\n",
      "{'loss': 0.1547, 'grad_norm': 4.501569747924805, 'learning_rate': 7.696969696969696e-05, 'epoch': 0.24}\n",
      "{'loss': 0.2329, 'grad_norm': 2.335115432739258, 'learning_rate': 7.676767676767676e-05, 'epoch': 0.24}\n",
      "{'loss': 0.2179, 'grad_norm': 1.8802013397216797, 'learning_rate': 7.656565656565658e-05, 'epoch': 0.24}\n",
      "{'loss': 0.1773, 'grad_norm': 3.431067943572998, 'learning_rate': 7.636363636363637e-05, 'epoch': 0.24}\n",
      "{'loss': 0.7208, 'grad_norm': 6.7979817390441895, 'learning_rate': 7.616161616161617e-05, 'epoch': 0.25}\n",
      "{'loss': 0.4684, 'grad_norm': 3.2450757026672363, 'learning_rate': 7.595959595959596e-05, 'epoch': 0.25}\n",
      "{'loss': 0.4629, 'grad_norm': 4.828105449676514, 'learning_rate': 7.575757575757576e-05, 'epoch': 0.25}\n",
      "{'loss': 0.1812, 'grad_norm': 1.6817439794540405, 'learning_rate': 7.555555555555556e-05, 'epoch': 0.25}\n",
      "{'loss': 0.525, 'grad_norm': 2.7678909301757812, 'learning_rate': 7.535353535353536e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0604, 'grad_norm': 0.5724742412567139, 'learning_rate': 7.515151515151515e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0854, 'grad_norm': 1.1764131784439087, 'learning_rate': 7.494949494949495e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1629, 'grad_norm': 3.7337896823883057, 'learning_rate': 7.474747474747475e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0789, 'grad_norm': 1.0854514837265015, 'learning_rate': 7.454545454545455e-05, 'epoch': 0.26}\n",
      "{'loss': 0.21, 'grad_norm': 2.5694162845611572, 'learning_rate': 7.434343434343435e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1916, 'grad_norm': 1.7814455032348633, 'learning_rate': 7.414141414141415e-05, 'epoch': 0.27}\n",
      "{'loss': 0.5118, 'grad_norm': 3.3211255073547363, 'learning_rate': 7.393939393939395e-05, 'epoch': 0.27}\n",
      "{'loss': 0.049, 'grad_norm': 2.672820806503296, 'learning_rate': 7.373737373737373e-05, 'epoch': 0.27}\n",
      "{'loss': 0.231, 'grad_norm': 2.532691717147827, 'learning_rate': 7.353535353535353e-05, 'epoch': 0.27}\n",
      "{'loss': 0.3571, 'grad_norm': 3.965944528579712, 'learning_rate': 7.333333333333333e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0332, 'grad_norm': 0.5069712996482849, 'learning_rate': 7.313131313131314e-05, 'epoch': 0.28}\n",
      "{'loss': 0.2198, 'grad_norm': 1.6661629676818848, 'learning_rate': 7.292929292929293e-05, 'epoch': 0.28}\n",
      "{'loss': 0.076, 'grad_norm': 1.1559007167816162, 'learning_rate': 7.272727272727273e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1097, 'grad_norm': 2.0872085094451904, 'learning_rate': 7.252525252525253e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0755, 'grad_norm': 1.020861029624939, 'learning_rate': 7.232323232323233e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1441, 'grad_norm': 2.177194356918335, 'learning_rate': 7.212121212121213e-05, 'epoch': 0.29}\n",
      "{'loss': 0.2085, 'grad_norm': 1.6100929975509644, 'learning_rate': 7.191919191919192e-05, 'epoch': 0.29}\n",
      "{'loss': 0.2797, 'grad_norm': 1.698237419128418, 'learning_rate': 7.171717171717171e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1994, 'grad_norm': 1.6402876377105713, 'learning_rate': 7.151515151515152e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3755, 'grad_norm': 3.9534428119659424, 'learning_rate': 7.131313131313132e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1399, 'grad_norm': 1.058664083480835, 'learning_rate': 7.111111111111112e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3493, 'grad_norm': 2.774402141571045, 'learning_rate': 7.090909090909092e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0999, 'grad_norm': 0.8684535026550293, 'learning_rate': 7.07070707070707e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0343, 'grad_norm': 0.37721091508865356, 'learning_rate': 7.05050505050505e-05, 'epoch': 0.3}\n",
      "{'loss': 0.247, 'grad_norm': 2.2338180541992188, 'learning_rate': 7.03030303030303e-05, 'epoch': 0.3}\n",
      "{'loss': 0.1696, 'grad_norm': 2.6168930530548096, 'learning_rate': 7.01010101010101e-05, 'epoch': 0.31}\n",
      "{'loss': 0.3787, 'grad_norm': 3.5337042808532715, 'learning_rate': 6.98989898989899e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1957, 'grad_norm': 3.987288475036621, 'learning_rate': 6.96969696969697e-05, 'epoch': 0.31}\n",
      "{'loss': 0.294, 'grad_norm': 3.920325994491577, 'learning_rate': 6.94949494949495e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1169, 'grad_norm': 2.981879234313965, 'learning_rate': 6.92929292929293e-05, 'epoch': 0.31}\n",
      "{'loss': 0.155, 'grad_norm': 2.4393789768218994, 'learning_rate': 6.90909090909091e-05, 'epoch': 0.32}\n",
      "{'loss': 0.311, 'grad_norm': 4.194166660308838, 'learning_rate': 6.88888888888889e-05, 'epoch': 0.32}\n",
      "{'loss': 0.2844, 'grad_norm': 1.4676367044448853, 'learning_rate': 6.86868686868687e-05, 'epoch': 0.32}\n",
      "{'loss': 0.2565, 'grad_norm': 2.350874662399292, 'learning_rate': 6.848484848484848e-05, 'epoch': 0.32}\n",
      "{'loss': 0.651, 'grad_norm': 4.362179756164551, 'learning_rate': 6.828282828282828e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0498, 'grad_norm': 0.8683914542198181, 'learning_rate': 6.808080808080809e-05, 'epoch': 0.33}\n",
      "{'loss': 0.2374, 'grad_norm': 1.2254458665847778, 'learning_rate': 6.787878787878789e-05, 'epoch': 0.33}\n",
      "{'loss': 0.3679, 'grad_norm': 1.9675164222717285, 'learning_rate': 6.767676767676769e-05, 'epoch': 0.33}\n",
      "{'loss': 0.076, 'grad_norm': 3.300075054168701, 'learning_rate': 6.747474747474747e-05, 'epoch': 0.33}\n",
      "{'loss': 0.585, 'grad_norm': 2.1370067596435547, 'learning_rate': 6.727272727272727e-05, 'epoch': 0.33}\n",
      "{'loss': 0.1173, 'grad_norm': 1.0870505571365356, 'learning_rate': 6.707070707070707e-05, 'epoch': 0.34}\n",
      "{'loss': 0.2341, 'grad_norm': 2.785132884979248, 'learning_rate': 6.686868686868687e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0518, 'grad_norm': 1.0202291011810303, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1611, 'grad_norm': 3.069092273712158, 'learning_rate': 6.646464646464647e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3356, 'grad_norm': 4.030818462371826, 'learning_rate': 6.626262626262627e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3323, 'grad_norm': 2.4610867500305176, 'learning_rate': 6.606060606060607e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0652, 'grad_norm': 1.06015145778656, 'learning_rate': 6.585858585858587e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0962, 'grad_norm': 1.2535908222198486, 'learning_rate': 6.565656565656566e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0496, 'grad_norm': 0.5531207323074341, 'learning_rate': 6.545454545454546e-05, 'epoch': 0.35}\n",
      "{'loss': 0.1747, 'grad_norm': 1.6494088172912598, 'learning_rate': 6.525252525252525e-05, 'epoch': 0.35}\n",
      "{'loss': 0.2823, 'grad_norm': 4.781968116760254, 'learning_rate': 6.505050505050505e-05, 'epoch': 0.36}\n",
      "{'loss': 0.134, 'grad_norm': 0.861386239528656, 'learning_rate': 6.484848484848485e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1388, 'grad_norm': 2.4450254440307617, 'learning_rate': 6.464646464646466e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1424, 'grad_norm': 1.2491099834442139, 'learning_rate': 6.444444444444446e-05, 'epoch': 0.36}\n",
      "{'loss': 0.2088, 'grad_norm': 2.686691999435425, 'learning_rate': 6.424242424242424e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1485, 'grad_norm': 1.6691046953201294, 'learning_rate': 6.404040404040404e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3419, 'grad_norm': 3.0871620178222656, 'learning_rate': 6.383838383838384e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1291, 'grad_norm': 1.4989640712738037, 'learning_rate': 6.363636363636364e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3709, 'grad_norm': 3.910581588745117, 'learning_rate': 6.343434343434344e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0719, 'grad_norm': 1.6538747549057007, 'learning_rate': 6.323232323232323e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1624, 'grad_norm': 1.626648187637329, 'learning_rate': 6.303030303030302e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1814, 'grad_norm': 2.957996368408203, 'learning_rate': 6.282828282828284e-05, 'epoch': 0.38}\n",
      "{'loss': 0.2442, 'grad_norm': 3.9954123497009277, 'learning_rate': 6.262626262626264e-05, 'epoch': 0.38}\n",
      "{'loss': 0.2261, 'grad_norm': 1.7937676906585693, 'learning_rate': 6.242424242424243e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0219, 'grad_norm': 0.2426939159631729, 'learning_rate': 6.222222222222222e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1519, 'grad_norm': 2.3656022548675537, 'learning_rate': 6.202020202020202e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0183, 'grad_norm': 0.25359344482421875, 'learning_rate': 6.181818181818182e-05, 'epoch': 0.39}\n",
      "{'loss': 0.1862, 'grad_norm': 1.6429917812347412, 'learning_rate': 6.161616161616162e-05, 'epoch': 0.39}\n",
      "{'loss': 0.1432, 'grad_norm': 2.023395538330078, 'learning_rate': 6.141414141414142e-05, 'epoch': 0.39}\n",
      "{'loss': 0.29, 'grad_norm': 3.562608003616333, 'learning_rate': 6.121212121212121e-05, 'epoch': 0.39}\n",
      "{'loss': 0.3474, 'grad_norm': 1.7956233024597168, 'learning_rate': 6.101010101010102e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1715, 'grad_norm': 2.068814754486084, 'learning_rate': 6.080808080808081e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1971, 'grad_norm': 2.251598596572876, 'learning_rate': 6.060606060606061e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec376cd2d5b401f89dbd9cfe98cd2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22132696211338043, 'eval_runtime': 31.8311, 'eval_samples_per_second': 15.708, 'eval_steps_per_second': 1.979, 'epoch': 0.4}\n",
      "{'loss': 0.043, 'grad_norm': 0.9014453887939453, 'learning_rate': 6.040404040404041e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0977, 'grad_norm': 2.2420949935913086, 'learning_rate': 6.02020202020202e-05, 'epoch': 0.4}\n",
      "{'loss': 0.2667, 'grad_norm': 3.604114055633545, 'learning_rate': 6e-05, 'epoch': 0.41}\n",
      "{'loss': 0.5034, 'grad_norm': 4.343308925628662, 'learning_rate': 5.97979797979798e-05, 'epoch': 0.41}\n",
      "{'loss': 0.1976, 'grad_norm': 2.286811113357544, 'learning_rate': 5.959595959595959e-05, 'epoch': 0.41}\n",
      "{'loss': 0.324, 'grad_norm': 3.273556709289551, 'learning_rate': 5.93939393939394e-05, 'epoch': 0.41}\n",
      "{'loss': 0.2518, 'grad_norm': 2.502521514892578, 'learning_rate': 5.91919191919192e-05, 'epoch': 0.41}\n",
      "{'loss': 0.109, 'grad_norm': 3.106017589569092, 'learning_rate': 5.8989898989898996e-05, 'epoch': 0.42}\n",
      "{'loss': 0.1586, 'grad_norm': 2.0380759239196777, 'learning_rate': 5.878787878787879e-05, 'epoch': 0.42}\n",
      "{'loss': 0.4278, 'grad_norm': 3.9419238567352295, 'learning_rate': 5.858585858585859e-05, 'epoch': 0.42}\n",
      "{'loss': 0.1134, 'grad_norm': 1.8560972213745117, 'learning_rate': 5.8383838383838386e-05, 'epoch': 0.42}\n",
      "{'loss': 0.131, 'grad_norm': 1.6663349866867065, 'learning_rate': 5.818181818181818e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2625, 'grad_norm': 5.251952171325684, 'learning_rate': 5.797979797979798e-05, 'epoch': 0.43}\n",
      "{'loss': 0.084, 'grad_norm': 0.9291982650756836, 'learning_rate': 5.7777777777777776e-05, 'epoch': 0.43}\n",
      "{'loss': 0.1143, 'grad_norm': 2.2463433742523193, 'learning_rate': 5.757575757575758e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0423, 'grad_norm': 0.9370580315589905, 'learning_rate': 5.737373737373738e-05, 'epoch': 0.43}\n",
      "{'loss': 0.1735, 'grad_norm': 3.684628963470459, 'learning_rate': 5.717171717171717e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0359, 'grad_norm': 0.3867456018924713, 'learning_rate': 5.696969696969697e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0407, 'grad_norm': 0.6648585200309753, 'learning_rate': 5.676767676767677e-05, 'epoch': 0.44}\n",
      "{'loss': 0.2405, 'grad_norm': 4.120439052581787, 'learning_rate': 5.6565656565656563e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1889, 'grad_norm': 1.3104071617126465, 'learning_rate': 5.636363636363636e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1192, 'grad_norm': 1.4591997861862183, 'learning_rate': 5.616161616161616e-05, 'epoch': 0.44}\n",
      "{'loss': 0.3563, 'grad_norm': 1.9931806325912476, 'learning_rate': 5.595959595959597e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1685, 'grad_norm': 2.1937336921691895, 'learning_rate': 5.5757575757575766e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0439, 'grad_norm': 2.221534490585327, 'learning_rate': 5.555555555555556e-05, 'epoch': 0.45}\n",
      "{'loss': 0.2462, 'grad_norm': 5.669356346130371, 'learning_rate': 5.535353535353536e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0283, 'grad_norm': 0.6650404334068298, 'learning_rate': 5.5151515151515156e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0786, 'grad_norm': 1.381569743156433, 'learning_rate': 5.494949494949495e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0713, 'grad_norm': 1.2705683708190918, 'learning_rate': 5.474747474747475e-05, 'epoch': 0.46}\n",
      "{'loss': 0.3108, 'grad_norm': 3.9274964332580566, 'learning_rate': 5.4545454545454546e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2306, 'grad_norm': 3.5660018920898438, 'learning_rate': 5.434343434343434e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2539, 'grad_norm': 11.73741626739502, 'learning_rate': 5.414141414141415e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0744, 'grad_norm': 2.1731836795806885, 'learning_rate': 5.393939393939394e-05, 'epoch': 0.47}\n",
      "{'loss': 0.1021, 'grad_norm': 3.3049910068511963, 'learning_rate': 5.373737373737374e-05, 'epoch': 0.47}\n",
      "{'loss': 0.3556, 'grad_norm': 7.849222660064697, 'learning_rate': 5.353535353535354e-05, 'epoch': 0.47}\n",
      "{'loss': 0.1313, 'grad_norm': 3.268040895462036, 'learning_rate': 5.333333333333333e-05, 'epoch': 0.47}\n",
      "{'loss': 0.1878, 'grad_norm': 4.633787155151367, 'learning_rate': 5.313131313131313e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0661, 'grad_norm': 0.7739184498786926, 'learning_rate': 5.292929292929293e-05, 'epoch': 0.48}\n",
      "{'loss': 0.1871, 'grad_norm': 2.343937873840332, 'learning_rate': 5.272727272727272e-05, 'epoch': 0.48}\n",
      "{'loss': 0.3324, 'grad_norm': 3.6026246547698975, 'learning_rate': 5.2525252525252536e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0397, 'grad_norm': 0.8864782452583313, 'learning_rate': 5.232323232323233e-05, 'epoch': 0.48}\n",
      "{'loss': 0.1648, 'grad_norm': 3.4493558406829834, 'learning_rate': 5.212121212121213e-05, 'epoch': 0.48}\n",
      "{'loss': 0.237, 'grad_norm': 5.334903240203857, 'learning_rate': 5.1919191919191926e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0503, 'grad_norm': 0.6632393598556519, 'learning_rate': 5.171717171717172e-05, 'epoch': 0.49}\n",
      "{'loss': 0.1908, 'grad_norm': 2.5059828758239746, 'learning_rate': 5.151515151515152e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0539, 'grad_norm': 1.0573140382766724, 'learning_rate': 5.1313131313131316e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0288, 'grad_norm': 0.5599038004875183, 'learning_rate': 5.111111111111111e-05, 'epoch': 0.49}\n",
      "{'loss': 0.1769, 'grad_norm': 2.0733554363250732, 'learning_rate': 5.090909090909091e-05, 'epoch': 0.5}\n",
      "{'loss': 0.1246, 'grad_norm': 2.624009370803833, 'learning_rate': 5.070707070707071e-05, 'epoch': 0.5}\n",
      "{'loss': 0.1625, 'grad_norm': 6.485532760620117, 'learning_rate': 5.050505050505051e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0392, 'grad_norm': 0.5764033198356628, 'learning_rate': 5.030303030303031e-05, 'epoch': 0.5}\n",
      "{'loss': 0.3637, 'grad_norm': 3.7616915702819824, 'learning_rate': 5.01010101010101e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0982, 'grad_norm': 1.7497409582138062, 'learning_rate': 4.98989898989899e-05, 'epoch': 0.51}\n",
      "{'loss': 0.4173, 'grad_norm': 2.0579214096069336, 'learning_rate': 4.9696969696969694e-05, 'epoch': 0.51}\n",
      "{'loss': 0.2425, 'grad_norm': 3.3961381912231445, 'learning_rate': 4.94949494949495e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0326, 'grad_norm': 0.6919016242027283, 'learning_rate': 4.92929292929293e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1111, 'grad_norm': 3.264331579208374, 'learning_rate': 4.909090909090909e-05, 'epoch': 0.51}\n",
      "{'loss': 0.3661, 'grad_norm': 7.990633487701416, 'learning_rate': 4.888888888888889e-05, 'epoch': 0.52}\n",
      "{'loss': 0.1793, 'grad_norm': 2.5004661083221436, 'learning_rate': 4.868686868686869e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0556, 'grad_norm': 1.144554853439331, 'learning_rate': 4.848484848484849e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0598, 'grad_norm': 1.4448717832565308, 'learning_rate': 4.828282828282829e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0965, 'grad_norm': 2.4819352626800537, 'learning_rate': 4.808080808080808e-05, 'epoch': 0.52}\n",
      "{'loss': 0.1625, 'grad_norm': 2.4747469425201416, 'learning_rate': 4.787878787878788e-05, 'epoch': 0.53}\n",
      "{'loss': 0.1687, 'grad_norm': 4.450168132781982, 'learning_rate': 4.7676767676767684e-05, 'epoch': 0.53}\n",
      "{'loss': 0.4478, 'grad_norm': 4.435345649719238, 'learning_rate': 4.7474747474747476e-05, 'epoch': 0.53}\n",
      "{'loss': 0.1602, 'grad_norm': 4.0902838706970215, 'learning_rate': 4.7272727272727275e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0505, 'grad_norm': 1.5769492387771606, 'learning_rate': 4.7070707070707074e-05, 'epoch': 0.53}\n",
      "{'loss': 0.2378, 'grad_norm': 1.2778849601745605, 'learning_rate': 4.686868686868687e-05, 'epoch': 0.54}\n",
      "{'loss': 0.1862, 'grad_norm': 2.920099973678589, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.54}\n",
      "{'loss': 0.1031, 'grad_norm': 7.5817952156066895, 'learning_rate': 4.6464646464646464e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0969, 'grad_norm': 1.3804373741149902, 'learning_rate': 4.626262626262626e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0814, 'grad_norm': 1.495803713798523, 'learning_rate': 4.606060606060607e-05, 'epoch': 0.54}\n",
      "{'loss': 0.1632, 'grad_norm': 2.447643995285034, 'learning_rate': 4.585858585858586e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1493, 'grad_norm': 3.7849740982055664, 'learning_rate': 4.565656565656566e-05, 'epoch': 0.55}\n",
      "{'loss': 0.2807, 'grad_norm': 1.062875509262085, 'learning_rate': 4.545454545454546e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1283, 'grad_norm': 4.789849758148193, 'learning_rate': 4.525252525252526e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3037, 'grad_norm': 3.4614546298980713, 'learning_rate': 4.5050505050505056e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1234, 'grad_norm': 1.8635555505752563, 'learning_rate': 4.484848484848485e-05, 'epoch': 0.56}\n",
      "{'loss': 0.2172, 'grad_norm': 5.215778350830078, 'learning_rate': 4.464646464646465e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0667, 'grad_norm': 2.436084270477295, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.56}\n",
      "{'loss': 0.4344, 'grad_norm': 3.058561325073242, 'learning_rate': 4.4242424242424246e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0356, 'grad_norm': 0.9401261806488037, 'learning_rate': 4.4040404040404044e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0961, 'grad_norm': 1.222967505455017, 'learning_rate': 4.383838383838384e-05, 'epoch': 0.57}\n",
      "{'loss': 0.1874, 'grad_norm': 4.33816385269165, 'learning_rate': 4.3636363636363636e-05, 'epoch': 0.57}\n",
      "{'loss': 0.1498, 'grad_norm': 2.2912395000457764, 'learning_rate': 4.343434343434344e-05, 'epoch': 0.57}\n",
      "{'loss': 0.2955, 'grad_norm': 1.3041361570358276, 'learning_rate': 4.3232323232323234e-05, 'epoch': 0.57}\n",
      "{'loss': 0.2477, 'grad_norm': 2.6553854942321777, 'learning_rate': 4.303030303030303e-05, 'epoch': 0.57}\n",
      "{'loss': 0.2974, 'grad_norm': 3.904984474182129, 'learning_rate': 4.282828282828283e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0848, 'grad_norm': 1.6349183320999146, 'learning_rate': 4.262626262626263e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0253, 'grad_norm': 0.41517284512519836, 'learning_rate': 4.242424242424243e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0641, 'grad_norm': 1.659530520439148, 'learning_rate': 4.222222222222222e-05, 'epoch': 0.58}\n",
      "{'loss': 0.2163, 'grad_norm': 1.9890776872634888, 'learning_rate': 4.202020202020202e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1776, 'grad_norm': 3.6057863235473633, 'learning_rate': 4.181818181818182e-05, 'epoch': 0.59}\n",
      "{'loss': 0.1868, 'grad_norm': 2.4628217220306396, 'learning_rate': 4.161616161616162e-05, 'epoch': 0.59}\n",
      "{'loss': 0.4349, 'grad_norm': 3.984203815460205, 'learning_rate': 4.141414141414142e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0573, 'grad_norm': 1.0408896207809448, 'learning_rate': 4.1212121212121216e-05, 'epoch': 0.59}\n",
      "{'loss': 0.1812, 'grad_norm': 2.6650755405426025, 'learning_rate': 4.101010101010101e-05, 'epoch': 0.59}\n",
      "{'loss': 0.1973, 'grad_norm': 2.834820508956909, 'learning_rate': 4.0808080808080814e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0669, 'grad_norm': 0.8513012528419495, 'learning_rate': 4.0606060606060606e-05, 'epoch': 0.6}\n",
      "{'loss': 0.1624, 'grad_norm': 3.6323471069335938, 'learning_rate': 4.0404040404040405e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f5e02ea3774364b73457cf946b6156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2025824934244156, 'eval_runtime': 32.0774, 'eval_samples_per_second': 15.587, 'eval_steps_per_second': 1.964, 'epoch': 0.6}\n",
      "{'loss': 0.2745, 'grad_norm': 3.250603437423706, 'learning_rate': 4.0202020202020204e-05, 'epoch': 0.6}\n",
      "{'loss': 0.026, 'grad_norm': 0.6206432580947876, 'learning_rate': 4e-05, 'epoch': 0.6}\n",
      "{'loss': 0.031, 'grad_norm': 0.5821423530578613, 'learning_rate': 3.97979797979798e-05, 'epoch': 0.61}\n",
      "{'loss': 0.2898, 'grad_norm': 6.44357442855835, 'learning_rate': 3.9595959595959594e-05, 'epoch': 0.61}\n",
      "{'loss': 0.2734, 'grad_norm': 2.770169496536255, 'learning_rate': 3.939393939393939e-05, 'epoch': 0.61}\n",
      "{'loss': 0.4613, 'grad_norm': 2.5390465259552, 'learning_rate': 3.91919191919192e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0785, 'grad_norm': 0.9323313236236572, 'learning_rate': 3.898989898989899e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0381, 'grad_norm': 1.109047293663025, 'learning_rate': 3.878787878787879e-05, 'epoch': 0.62}\n",
      "{'loss': 0.3027, 'grad_norm': 2.4068987369537354, 'learning_rate': 3.858585858585859e-05, 'epoch': 0.62}\n",
      "{'loss': 0.1617, 'grad_norm': 1.0561012029647827, 'learning_rate': 3.838383838383838e-05, 'epoch': 0.62}\n",
      "{'loss': 0.1864, 'grad_norm': 3.599985122680664, 'learning_rate': 3.818181818181819e-05, 'epoch': 0.62}\n",
      "{'loss': 0.1642, 'grad_norm': 2.3433032035827637, 'learning_rate': 3.797979797979798e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0715, 'grad_norm': 1.4149665832519531, 'learning_rate': 3.777777777777778e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0877, 'grad_norm': 1.2670481204986572, 'learning_rate': 3.757575757575758e-05, 'epoch': 0.63}\n",
      "{'loss': 0.2466, 'grad_norm': 2.7512569427490234, 'learning_rate': 3.7373737373737376e-05, 'epoch': 0.63}\n",
      "{'loss': 0.1516, 'grad_norm': 1.8258166313171387, 'learning_rate': 3.7171717171717175e-05, 'epoch': 0.63}\n",
      "{'loss': 0.6387, 'grad_norm': 2.458449125289917, 'learning_rate': 3.6969696969696974e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3711, 'grad_norm': 2.9886176586151123, 'learning_rate': 3.6767676767676766e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2655, 'grad_norm': 1.5747921466827393, 'learning_rate': 3.656565656565657e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1399, 'grad_norm': 3.094666004180908, 'learning_rate': 3.6363636363636364e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0931, 'grad_norm': 2.5152587890625, 'learning_rate': 3.616161616161616e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0531, 'grad_norm': 0.7366706728935242, 'learning_rate': 3.595959595959596e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2299, 'grad_norm': 7.9258198738098145, 'learning_rate': 3.575757575757576e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0836, 'grad_norm': 1.0221633911132812, 'learning_rate': 3.555555555555556e-05, 'epoch': 0.65}\n",
      "{'loss': 0.1077, 'grad_norm': 1.499254822731018, 'learning_rate': 3.535353535353535e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0396, 'grad_norm': 0.7818360328674316, 'learning_rate': 3.515151515151515e-05, 'epoch': 0.65}\n",
      "{'loss': 0.156, 'grad_norm': 1.9721471071243286, 'learning_rate': 3.494949494949495e-05, 'epoch': 0.65}\n",
      "{'loss': 0.1069, 'grad_norm': 2.2288246154785156, 'learning_rate': 3.474747474747475e-05, 'epoch': 0.66}\n",
      "{'loss': 0.1614, 'grad_norm': 1.4078952074050903, 'learning_rate': 3.454545454545455e-05, 'epoch': 0.66}\n",
      "{'loss': 0.5998, 'grad_norm': 3.1320903301239014, 'learning_rate': 3.434343434343435e-05, 'epoch': 0.66}\n",
      "{'loss': 0.1347, 'grad_norm': 3.294796943664551, 'learning_rate': 3.414141414141414e-05, 'epoch': 0.66}\n",
      "{'loss': 0.2225, 'grad_norm': 6.953677654266357, 'learning_rate': 3.3939393939393945e-05, 'epoch': 0.66}\n",
      "{'loss': 0.2075, 'grad_norm': 5.662921905517578, 'learning_rate': 3.373737373737374e-05, 'epoch': 0.67}\n",
      "{'loss': 0.177, 'grad_norm': 5.4127302169799805, 'learning_rate': 3.3535353535353536e-05, 'epoch': 0.67}\n",
      "{'loss': 0.1254, 'grad_norm': 0.7999169230461121, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.67}\n",
      "{'loss': 0.1111, 'grad_norm': 1.7629629373550415, 'learning_rate': 3.3131313131313134e-05, 'epoch': 0.67}\n",
      "{'loss': 0.2523, 'grad_norm': 5.656398773193359, 'learning_rate': 3.292929292929293e-05, 'epoch': 0.67}\n",
      "{'loss': 0.2283, 'grad_norm': 2.00860857963562, 'learning_rate': 3.272727272727273e-05, 'epoch': 0.68}\n",
      "{'loss': 0.2647, 'grad_norm': 1.589140772819519, 'learning_rate': 3.2525252525252524e-05, 'epoch': 0.68}\n",
      "{'loss': 0.4501, 'grad_norm': 2.3983070850372314, 'learning_rate': 3.232323232323233e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0383, 'grad_norm': 0.5738098621368408, 'learning_rate': 3.212121212121212e-05, 'epoch': 0.68}\n",
      "{'loss': 0.043, 'grad_norm': 0.9349002838134766, 'learning_rate': 3.191919191919192e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0645, 'grad_norm': 0.8211035132408142, 'learning_rate': 3.171717171717172e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0216, 'grad_norm': 0.7899746298789978, 'learning_rate': 3.151515151515151e-05, 'epoch': 0.69}\n",
      "{'loss': 0.2027, 'grad_norm': 1.717010259628296, 'learning_rate': 3.131313131313132e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0645, 'grad_norm': 1.1134041547775269, 'learning_rate': 3.111111111111111e-05, 'epoch': 0.69}\n",
      "{'loss': 0.2439, 'grad_norm': 2.3269317150115967, 'learning_rate': 3.090909090909091e-05, 'epoch': 0.69}\n",
      "{'loss': 0.2685, 'grad_norm': 4.755545139312744, 'learning_rate': 3.070707070707071e-05, 'epoch': 0.7}\n",
      "{'loss': 0.117, 'grad_norm': 1.9082615375518799, 'learning_rate': 3.050505050505051e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2057, 'grad_norm': 3.6443519592285156, 'learning_rate': 3.0303030303030306e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0943, 'grad_norm': 3.4461560249328613, 'learning_rate': 3.01010101010101e-05, 'epoch': 0.7}\n",
      "{'loss': 0.267, 'grad_norm': 3.485018491744995, 'learning_rate': 2.98989898989899e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1709, 'grad_norm': 3.236036777496338, 'learning_rate': 2.96969696969697e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0712, 'grad_norm': 1.1830713748931885, 'learning_rate': 2.9494949494949498e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0676, 'grad_norm': 1.9092469215393066, 'learning_rate': 2.9292929292929294e-05, 'epoch': 0.71}\n",
      "{'loss': 0.1599, 'grad_norm': 3.002110004425049, 'learning_rate': 2.909090909090909e-05, 'epoch': 0.71}\n",
      "{'loss': 0.1476, 'grad_norm': 1.6081633567810059, 'learning_rate': 2.8888888888888888e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0404, 'grad_norm': 0.5646381974220276, 'learning_rate': 2.868686868686869e-05, 'epoch': 0.72}\n",
      "{'loss': 0.2656, 'grad_norm': 2.3820483684539795, 'learning_rate': 2.8484848484848486e-05, 'epoch': 0.72}\n",
      "{'loss': 0.1062, 'grad_norm': 1.1171773672103882, 'learning_rate': 2.8282828282828282e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0747, 'grad_norm': 1.1364004611968994, 'learning_rate': 2.808080808080808e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3059, 'grad_norm': 3.2377638816833496, 'learning_rate': 2.7878787878787883e-05, 'epoch': 0.72}\n",
      "{'loss': 0.5237, 'grad_norm': 2.990751028060913, 'learning_rate': 2.767676767676768e-05, 'epoch': 0.73}\n",
      "{'loss': 0.2116, 'grad_norm': 3.1088931560516357, 'learning_rate': 2.7474747474747474e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0417, 'grad_norm': 1.0060609579086304, 'learning_rate': 2.7272727272727273e-05, 'epoch': 0.73}\n",
      "{'loss': 0.2595, 'grad_norm': 2.2197391986846924, 'learning_rate': 2.7070707070707075e-05, 'epoch': 0.73}\n",
      "{'loss': 0.3887, 'grad_norm': 3.569201707839966, 'learning_rate': 2.686868686868687e-05, 'epoch': 0.73}\n",
      "{'loss': 0.1372, 'grad_norm': 2.8916094303131104, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.74}\n",
      "{'loss': 0.3821, 'grad_norm': 1.9645317792892456, 'learning_rate': 2.6464646464646466e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0809, 'grad_norm': 0.6242738962173462, 'learning_rate': 2.6262626262626268e-05, 'epoch': 0.74}\n",
      "{'loss': 0.1708, 'grad_norm': 1.041839838027954, 'learning_rate': 2.6060606060606063e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0518, 'grad_norm': 1.32998526096344, 'learning_rate': 2.585858585858586e-05, 'epoch': 0.74}\n",
      "{'loss': 0.4848, 'grad_norm': 2.3727989196777344, 'learning_rate': 2.5656565656565658e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0321, 'grad_norm': 0.5485222339630127, 'learning_rate': 2.5454545454545454e-05, 'epoch': 0.75}\n",
      "{'loss': 0.1424, 'grad_norm': 3.004108190536499, 'learning_rate': 2.5252525252525256e-05, 'epoch': 0.75}\n",
      "{'loss': 0.2171, 'grad_norm': 2.927858829498291, 'learning_rate': 2.505050505050505e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0891, 'grad_norm': 2.056093215942383, 'learning_rate': 2.4848484848484847e-05, 'epoch': 0.75}\n",
      "{'loss': 0.2169, 'grad_norm': 2.834538459777832, 'learning_rate': 2.464646464646465e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1045, 'grad_norm': 2.448594093322754, 'learning_rate': 2.4444444444444445e-05, 'epoch': 0.76}\n",
      "{'loss': 0.257, 'grad_norm': 2.9130067825317383, 'learning_rate': 2.4242424242424244e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2792, 'grad_norm': 3.170841932296753, 'learning_rate': 2.404040404040404e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0845, 'grad_norm': 1.1985888481140137, 'learning_rate': 2.3838383838383842e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2847, 'grad_norm': 1.7762371301651, 'learning_rate': 2.3636363636363637e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0747, 'grad_norm': 1.451642394065857, 'learning_rate': 2.3434343434343436e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1466, 'grad_norm': 3.6251142024993896, 'learning_rate': 2.3232323232323232e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1943, 'grad_norm': 1.3170403242111206, 'learning_rate': 2.3030303030303034e-05, 'epoch': 0.77}\n",
      "{'loss': 0.112, 'grad_norm': 1.3124830722808838, 'learning_rate': 2.282828282828283e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0962, 'grad_norm': 0.9225607514381409, 'learning_rate': 2.262626262626263e-05, 'epoch': 0.78}\n",
      "{'loss': 0.1683, 'grad_norm': 1.2087419033050537, 'learning_rate': 2.2424242424242424e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0207, 'grad_norm': 0.2721186578273773, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.78}\n",
      "{'loss': 0.201, 'grad_norm': 2.3066227436065674, 'learning_rate': 2.2020202020202022e-05, 'epoch': 0.78}\n",
      "{'loss': 0.1512, 'grad_norm': 2.0364058017730713, 'learning_rate': 2.1818181818181818e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0182, 'grad_norm': 0.26757749915122986, 'learning_rate': 2.1616161616161617e-05, 'epoch': 0.79}\n",
      "{'loss': 0.2069, 'grad_norm': 1.4994581937789917, 'learning_rate': 2.1414141414141416e-05, 'epoch': 0.79}\n",
      "{'loss': 0.0596, 'grad_norm': 0.7382340431213379, 'learning_rate': 2.1212121212121215e-05, 'epoch': 0.79}\n",
      "{'loss': 0.4218, 'grad_norm': 1.5196197032928467, 'learning_rate': 2.101010101010101e-05, 'epoch': 0.79}\n",
      "{'loss': 0.2824, 'grad_norm': 1.8544938564300537, 'learning_rate': 2.080808080808081e-05, 'epoch': 0.79}\n",
      "{'loss': 0.0657, 'grad_norm': 2.45143723487854, 'learning_rate': 2.0606060606060608e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2525, 'grad_norm': 3.8247976303100586, 'learning_rate': 2.0404040404040407e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0898, 'grad_norm': 2.2142140865325928, 'learning_rate': 2.0202020202020203e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4344c133f74f59b17d236b48a2e7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.183831587433815, 'eval_runtime': 32.2403, 'eval_samples_per_second': 15.509, 'eval_steps_per_second': 1.954, 'epoch': 0.8}\n",
      "{'loss': 0.0471, 'grad_norm': 1.891419529914856, 'learning_rate': 2e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0643, 'grad_norm': 0.9776850342750549, 'learning_rate': 1.9797979797979797e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1155, 'grad_norm': 1.8125966787338257, 'learning_rate': 1.95959595959596e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0845, 'grad_norm': 2.1320297718048096, 'learning_rate': 1.9393939393939395e-05, 'epoch': 0.81}\n",
      "{'loss': 0.2836, 'grad_norm': 3.260908842086792, 'learning_rate': 1.919191919191919e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0498, 'grad_norm': 0.8785823583602905, 'learning_rate': 1.898989898989899e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0532, 'grad_norm': 0.8955144286155701, 'learning_rate': 1.878787878787879e-05, 'epoch': 0.81}\n",
      "{'loss': 0.1276, 'grad_norm': 1.9700326919555664, 'learning_rate': 1.8585858585858588e-05, 'epoch': 0.82}\n",
      "{'loss': 0.2541, 'grad_norm': 1.7219291925430298, 'learning_rate': 1.8383838383838383e-05, 'epoch': 0.82}\n",
      "{'loss': 0.1027, 'grad_norm': 5.0520172119140625, 'learning_rate': 1.8181818181818182e-05, 'epoch': 0.82}\n",
      "{'loss': 0.1642, 'grad_norm': 3.9493868350982666, 'learning_rate': 1.797979797979798e-05, 'epoch': 0.82}\n",
      "{'loss': 0.1942, 'grad_norm': 1.708953857421875, 'learning_rate': 1.777777777777778e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0109, 'grad_norm': 0.15209098160266876, 'learning_rate': 1.7575757575757576e-05, 'epoch': 0.83}\n",
      "{'loss': 0.1271, 'grad_norm': 3.3988187313079834, 'learning_rate': 1.7373737373737375e-05, 'epoch': 0.83}\n",
      "{'loss': 0.1014, 'grad_norm': 1.1384176015853882, 'learning_rate': 1.7171717171717173e-05, 'epoch': 0.83}\n",
      "{'loss': 0.3276, 'grad_norm': 1.692399024963379, 'learning_rate': 1.6969696969696972e-05, 'epoch': 0.83}\n",
      "{'loss': 0.1969, 'grad_norm': 1.4162720441818237, 'learning_rate': 1.6767676767676768e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0843, 'grad_norm': 2.0710291862487793, 'learning_rate': 1.6565656565656567e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0638, 'grad_norm': 1.324081540107727, 'learning_rate': 1.6363636363636366e-05, 'epoch': 0.84}\n",
      "{'loss': 0.4366, 'grad_norm': 2.9285521507263184, 'learning_rate': 1.6161616161616165e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2592, 'grad_norm': 2.596068859100342, 'learning_rate': 1.595959595959596e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2272, 'grad_norm': 1.9084112644195557, 'learning_rate': 1.5757575757575756e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2396, 'grad_norm': 3.264850616455078, 'learning_rate': 1.5555555555555555e-05, 'epoch': 0.85}\n",
      "{'loss': 0.1044, 'grad_norm': 2.185429811477661, 'learning_rate': 1.5353535353535354e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0995, 'grad_norm': 1.7349660396575928, 'learning_rate': 1.5151515151515153e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3445, 'grad_norm': 1.0215109586715698, 'learning_rate': 1.494949494949495e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3263, 'grad_norm': 2.0077710151672363, 'learning_rate': 1.4747474747474749e-05, 'epoch': 0.85}\n",
      "{'loss': 0.4173, 'grad_norm': 2.0761327743530273, 'learning_rate': 1.4545454545454545e-05, 'epoch': 0.86}\n",
      "{'loss': 0.306, 'grad_norm': 5.381741046905518, 'learning_rate': 1.4343434343434345e-05, 'epoch': 0.86}\n",
      "{'loss': 0.067, 'grad_norm': 0.904791533946991, 'learning_rate': 1.4141414141414141e-05, 'epoch': 0.86}\n",
      "{'loss': 0.4661, 'grad_norm': 4.063493728637695, 'learning_rate': 1.3939393939393942e-05, 'epoch': 0.86}\n",
      "{'loss': 0.0232, 'grad_norm': 0.3205910921096802, 'learning_rate': 1.3737373737373737e-05, 'epoch': 0.86}\n",
      "{'loss': 0.1045, 'grad_norm': 1.477209210395813, 'learning_rate': 1.3535353535353538e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0773, 'grad_norm': 1.5594186782836914, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0573, 'grad_norm': 1.194817066192627, 'learning_rate': 1.3131313131313134e-05, 'epoch': 0.87}\n",
      "{'loss': 0.2329, 'grad_norm': 1.8092010021209717, 'learning_rate': 1.292929292929293e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0501, 'grad_norm': 0.8484627604484558, 'learning_rate': 1.2727272727272727e-05, 'epoch': 0.87}\n",
      "{'loss': 0.1193, 'grad_norm': 2.855470657348633, 'learning_rate': 1.2525252525252526e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0362, 'grad_norm': 0.5988473296165466, 'learning_rate': 1.2323232323232325e-05, 'epoch': 0.88}\n",
      "{'loss': 0.051, 'grad_norm': 1.4740949869155884, 'learning_rate': 1.2121212121212122e-05, 'epoch': 0.88}\n",
      "{'loss': 0.2153, 'grad_norm': 3.2120094299316406, 'learning_rate': 1.1919191919191921e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0387, 'grad_norm': 0.7802184224128723, 'learning_rate': 1.1717171717171718e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0839, 'grad_norm': 2.2255618572235107, 'learning_rate': 1.1515151515151517e-05, 'epoch': 0.89}\n",
      "{'loss': 0.1587, 'grad_norm': 1.5817477703094482, 'learning_rate': 1.1313131313131314e-05, 'epoch': 0.89}\n",
      "{'loss': 0.1566, 'grad_norm': 3.2555971145629883, 'learning_rate': 1.1111111111111112e-05, 'epoch': 0.89}\n",
      "{'loss': 0.278, 'grad_norm': 6.329399108886719, 'learning_rate': 1.0909090909090909e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0808, 'grad_norm': 1.501871943473816, 'learning_rate': 1.0707070707070708e-05, 'epoch': 0.89}\n",
      "{'loss': 0.021, 'grad_norm': 0.4336085915565491, 'learning_rate': 1.0505050505050505e-05, 'epoch': 0.9}\n",
      "{'loss': 0.1294, 'grad_norm': 1.4662072658538818, 'learning_rate': 1.0303030303030304e-05, 'epoch': 0.9}\n",
      "{'loss': 0.0802, 'grad_norm': 1.2374272346496582, 'learning_rate': 1.0101010101010101e-05, 'epoch': 0.9}\n",
      "{'loss': 0.2183, 'grad_norm': 1.0645843744277954, 'learning_rate': 9.898989898989899e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1025, 'grad_norm': 2.207160234451294, 'learning_rate': 9.696969696969698e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0446, 'grad_norm': 1.2570710182189941, 'learning_rate': 9.494949494949495e-06, 'epoch': 0.91}\n",
      "{'loss': 0.2091, 'grad_norm': 5.146381378173828, 'learning_rate': 9.292929292929294e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0461, 'grad_norm': 1.093583106994629, 'learning_rate': 9.090909090909091e-06, 'epoch': 0.91}\n",
      "{'loss': 0.2431, 'grad_norm': 3.7048559188842773, 'learning_rate': 8.88888888888889e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0264, 'grad_norm': 0.3732673227787018, 'learning_rate': 8.686868686868687e-06, 'epoch': 0.91}\n",
      "{'loss': 0.388, 'grad_norm': 4.107035160064697, 'learning_rate': 8.484848484848486e-06, 'epoch': 0.92}\n",
      "{'loss': 0.2466, 'grad_norm': 2.180934190750122, 'learning_rate': 8.282828282828283e-06, 'epoch': 0.92}\n",
      "{'loss': 0.1116, 'grad_norm': 1.8063805103302002, 'learning_rate': 8.080808080808082e-06, 'epoch': 0.92}\n",
      "{'loss': 0.1419, 'grad_norm': 1.8363947868347168, 'learning_rate': 7.878787878787878e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0912, 'grad_norm': 2.3930578231811523, 'learning_rate': 7.676767676767677e-06, 'epoch': 0.92}\n",
      "{'loss': 0.5012, 'grad_norm': 4.447259902954102, 'learning_rate': 7.474747474747475e-06, 'epoch': 0.93}\n",
      "{'loss': 0.1132, 'grad_norm': 2.0701513290405273, 'learning_rate': 7.272727272727272e-06, 'epoch': 0.93}\n",
      "{'loss': 0.4603, 'grad_norm': 3.836867094039917, 'learning_rate': 7.0707070707070704e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0354, 'grad_norm': 0.5020897388458252, 'learning_rate': 6.8686868686868685e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0348, 'grad_norm': 0.6506364345550537, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.93}\n",
      "{'loss': 0.2028, 'grad_norm': 3.2889010906219482, 'learning_rate': 6.464646464646465e-06, 'epoch': 0.94}\n",
      "{'loss': 0.1692, 'grad_norm': 4.343551158905029, 'learning_rate': 6.262626262626263e-06, 'epoch': 0.94}\n",
      "{'loss': 0.2306, 'grad_norm': 3.9169082641601562, 'learning_rate': 6.060606060606061e-06, 'epoch': 0.94}\n",
      "{'loss': 0.2206, 'grad_norm': 3.1324026584625244, 'learning_rate': 5.858585858585859e-06, 'epoch': 0.94}\n",
      "{'loss': 0.1644, 'grad_norm': 0.9112381339073181, 'learning_rate': 5.656565656565657e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0405, 'grad_norm': 0.647737443447113, 'learning_rate': 5.4545454545454545e-06, 'epoch': 0.95}\n",
      "{'loss': 0.2789, 'grad_norm': 2.1804356575012207, 'learning_rate': 5.2525252525252526e-06, 'epoch': 0.95}\n",
      "{'loss': 0.1746, 'grad_norm': 1.5956395864486694, 'learning_rate': 5.050505050505051e-06, 'epoch': 0.95}\n",
      "{'loss': 0.0741, 'grad_norm': 1.746951937675476, 'learning_rate': 4.848484848484849e-06, 'epoch': 0.95}\n",
      "{'loss': 0.1985, 'grad_norm': 11.443323135375977, 'learning_rate': 4.646464646464647e-06, 'epoch': 0.95}\n",
      "{'loss': 0.4073, 'grad_norm': 3.9949769973754883, 'learning_rate': 4.444444444444445e-06, 'epoch': 0.96}\n",
      "{'loss': 0.1001, 'grad_norm': 2.903531551361084, 'learning_rate': 4.242424242424243e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0265, 'grad_norm': 0.48220908641815186, 'learning_rate': 4.040404040404041e-06, 'epoch': 0.96}\n",
      "{'loss': 0.1639, 'grad_norm': 2.9533143043518066, 'learning_rate': 3.8383838383838385e-06, 'epoch': 0.96}\n",
      "{'loss': 0.2667, 'grad_norm': 2.5935633182525635, 'learning_rate': 3.636363636363636e-06, 'epoch': 0.96}\n",
      "{'loss': 0.082, 'grad_norm': 0.7721672654151917, 'learning_rate': 3.4343434343434343e-06, 'epoch': 0.97}\n",
      "{'loss': 0.1922, 'grad_norm': 2.5893683433532715, 'learning_rate': 3.2323232323232324e-06, 'epoch': 0.97}\n",
      "{'loss': 0.2513, 'grad_norm': 3.514284610748291, 'learning_rate': 3.0303030303030305e-06, 'epoch': 0.97}\n",
      "{'loss': 0.4776, 'grad_norm': 6.559989929199219, 'learning_rate': 2.8282828282828286e-06, 'epoch': 0.97}\n",
      "{'loss': 0.2972, 'grad_norm': 2.994227647781372, 'learning_rate': 2.6262626262626263e-06, 'epoch': 0.97}\n",
      "{'loss': 0.1946, 'grad_norm': 2.026249408721924, 'learning_rate': 2.4242424242424244e-06, 'epoch': 0.98}\n",
      "{'loss': 0.4549, 'grad_norm': 2.6614768505096436, 'learning_rate': 2.2222222222222225e-06, 'epoch': 0.98}\n",
      "{'loss': 0.0269, 'grad_norm': 0.29827746748924255, 'learning_rate': 2.0202020202020206e-06, 'epoch': 0.98}\n",
      "{'loss': 0.1629, 'grad_norm': 1.502488136291504, 'learning_rate': 1.818181818181818e-06, 'epoch': 0.98}\n",
      "{'loss': 0.0732, 'grad_norm': 2.1283793449401855, 'learning_rate': 1.6161616161616162e-06, 'epoch': 0.98}\n",
      "{'loss': 0.0727, 'grad_norm': 2.3769102096557617, 'learning_rate': 1.4141414141414143e-06, 'epoch': 0.99}\n",
      "{'loss': 0.2354, 'grad_norm': 1.4129637479782104, 'learning_rate': 1.2121212121212122e-06, 'epoch': 0.99}\n",
      "{'loss': 0.0591, 'grad_norm': 0.7462468147277832, 'learning_rate': 1.0101010101010103e-06, 'epoch': 0.99}\n",
      "{'loss': 0.178, 'grad_norm': 1.271016240119934, 'learning_rate': 8.080808080808081e-07, 'epoch': 0.99}\n",
      "{'loss': 0.034, 'grad_norm': 0.3169323205947876, 'learning_rate': 6.060606060606061e-07, 'epoch': 0.99}\n",
      "{'loss': 0.2173, 'grad_norm': 5.287325382232666, 'learning_rate': 4.0404040404040405e-07, 'epoch': 1.0}\n",
      "{'loss': 0.2947, 'grad_norm': 1.601010799407959, 'learning_rate': 2.0202020202020202e-07, 'epoch': 1.0}\n",
      "{'loss': 0.067, 'grad_norm': 0.9057210087776184, 'learning_rate': 0.0, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85e5ae294af42209bfe711fc6ea2cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1790277063846588, 'eval_runtime': 32.5333, 'eval_samples_per_second': 15.369, 'eval_steps_per_second': 1.936, 'epoch': 1.0}\n",
      "{'train_runtime': 1071.3587, 'train_samples_per_second': 3.734, 'train_steps_per_second': 0.467, 'train_loss': 0.21978609014302491, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = []\n",
    "\n",
    "FastLanguageModel.for_inference(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "니노이 아키노 국제공항이 처음으로 국내선을 운영한 시기는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "터미널 공식적으로 선택한 국내선으로 2008년 7월 22일(처음에는 세부 퍼시픽만, 그 필리핀 항공의 자회사 항공 필리핀과 PAL 익스프레스)에서, 세부 퍼시픽과 함께 문을 열었다. 국제선은 8월 1일 2008년이다. PAL에서 제외한 모든 국제 작전에서 사용하는 3번 터미널에서 미래에 운영하고, 원래에서 움직이겠다는 제안을 위한 것이다.그의 처음 2년 동안 2010년, 하지만 국내 항공사 세부 퍼시픽과 에어 필 익스프레스(그 항공 필리핀 그리고 그들은 PAL 익스프레스)의 4분기 남아 있는 유일한 세입자들이다. 작동 국제선의 대부분은 터미널 1부터 전 일본 항공은 첫 외국계 항공사 터미널 3은 2월 27일에 운영되는 것을 제외하고 운영되고 있다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 2008년 7월 22일\n",
      "\n",
      "PRED\n",
      " 2008년 8월 1일<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "주한일본공사의 스즈키는 누구를 카라와 함께 일본의 신한류를 이끄는 그룹이라 언급했는가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "소녀시대는 한류를 이끄는 주역으로도 인정 받고 있다. 주한일본공사 스즈키 히로시는 이들을 카라와 함께 일본의 신한류를 이끄는 그룹이라고 말했으며, 《경향신문》에서는 \"소녀시대는 대중문화의 아이콘, 아시아를 넘어 유럽까지 진출한 한류의 선두주자가 됐다\"라며 \"한류 열풍 이끄는 아시아 최고 걸그룹\"이라고 말했다. 브라질의 연예 프로그램인 ‘Leitura Dinamica’는 브라질의 k-pop 열풍을 소개하며 소녀시대를 예로 들며, “신곡 ‘훗’은 브라질 뿐 아니라 세계 유명 DJ들에게도 큰 인기다. 그야말로 소녀시대가 쏜 화살이 아시아를 넘어 세계로 날아가고 있는 셈”이라고 호평했다. 또 아리랑TV가 연 ‘K POP - 따라하기’에서 가장 많이 패러디된 가수는 소녀시대였으며, 인도네시아 팬들은 소녀시대의 라이브 공연을 자국에서 해 달라고 서명 운동을 벌이기도 했다. 소시지룩, 마린룩 등 패션은 대한민국에서 인기를 끌었으며, 특히 후루야 마사유키는 그들이 일본 젊은 여성들의 패션 아이콘이라고 말했다. 또한 일본 영어 교과서에 “전 세계에서 인기를 얻고 있는 K-pop 스타들”이라는 제목으로 K-pop의 대표로 소녀시대를 소개하며 사진이 삽입되었다. KIIS의 음악 감독인 줄리 필랏 (Julie Pilat)은 2012년 주목할 그룹으로 뽑기도 했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 소녀시대\n",
      "\n",
      "PRED\n",
      " 소녀시대<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "변희재가 운영했던 인터넷사이트는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2003년 2월 12일 KBS 신임 사장 인선 관련 공청회에 참여했을 때는 코드 인사, 낙하산 인사가 아닌 방송을 잘 아는 인물이 선임되어야 한다는 견해를 피력하였다. 당시 인터넷사이트 '서프라이즈' 운영자였던 변희재는 \"KBS 사장은 늘 '지사풍'의 언론인이 와야 한다는 강박관념이 잘못된 인선을 부른다\"며 \"지금 이 자리에서 언급되고 있는 언론인 정모씨나 강모 교수가 사장으로 선임이 된다고 해도 보도국과 교양프로만 챙기는 사장이 될 것이다. 언론인 중 방송을 아는 인물이 와서 현재 문제가 많은 오락프로 등도 개선해야 할 것\"이라고 밝혔다. 그는 또 \"시청률에 대한 부담이 상대적으로 덜한 KBS는 이제 '공정성'이라는 말보다는 '실험성'을 강조해야 할 것\"이라고 강조했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 서프라이즈\n",
      "\n",
      "PRED\n",
      " 서프라이즈<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][2])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "어디서 개복치를 식용으로 파는것을 금지하는가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "한국과 일본, 대만에서는 식용으로 먹기도 하는데 몸체의 대부분을 먹을 수 있다. 맛과 모양은 기름기가 많아 하얗고 뽀얀 편이라 참치 흰살과 비슷하다. 회로 먹기도 하는데 비린내가 안 나는 편이나 기름이 소화가 잘 안 돼, 많이 먹으면 설사를 유발하기도 한다. 등 쪽에서 나오는 흰색의 창자는 중국에선 용창이라는 이름으로 별미로 여겨지기도 하며 지느러미를 몸통의 살보다 별미로 취급한다. 껍질은 삶으면 흐물흐물해지는데, 이것을 우뭇가사리와 비슷하게 만들어 먹을 수 있다. 어떤 지역에서는 약재로 쓰이기도 한다. 대한민국에서는 포항 지역에서 개복치를 대소사에 쓰이는 별미 재료로 사용해 왔다. 구체적으로 껍질은 수육, 뱃살은 회무침용, 머리뼈와 머릿살은 찜 요리 재료로 사용한다. 근육 부분은 갈아서 부산 어묵에 들어가는 경우도 있다. 한편 유럽 연합에서는 개복치를 식용으로 파는 것이 금지되어 있다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 유럽 연합\n",
      "\n",
      "PRED\n",
      " 유럽 연합<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][3])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정답</th>\n",
       "      <th>학습전 출력</th>\n",
       "      <th>학습후 출력</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008년 7월 22일</td>\n",
       "      <td>니노이 아키노 국제공항이 처음으로 domestically 선을 운영한 시기는 200...</td>\n",
       "      <td>2008년 8월 1일&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>소녀시대</td>\n",
       "      <td>소녀시대가 주한일본공사의 스즈키 히로시는 카라와 함께 일본의 신한류를 이끄는 그룹이...</td>\n",
       "      <td>소녀시대&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>서프라이즈</td>\n",
       "      <td>변희재는 서프라이즈(이론적意义에서 보도용의로 보는가? ) 운영자 였다.&lt;|eot_id|&gt;</td>\n",
       "      <td>서프라이즈&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>유럽 연합</td>\n",
       "      <td>유럽 연합&lt;|eot_id|&gt;</td>\n",
       "      <td>유럽 연합&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             정답                                             학습전 출력  \\\n",
       "0  2008년 7월 22일  니노이 아키노 국제공항이 처음으로 domestically 선을 운영한 시기는 200...   \n",
       "1          소녀시대  소녀시대가 주한일본공사의 스즈키 히로시는 카라와 함께 일본의 신한류를 이끄는 그룹이...   \n",
       "2         서프라이즈  변희재는 서프라이즈(이론적意义에서 보도용의로 보는가? ) 운영자 였다.<|eot_id|>   \n",
       "3         유럽 연합                                    유럽 연합<|eot_id|>   \n",
       "\n",
       "                  학습후 출력  \n",
       "0  2008년 8월 1일<|eot_id|>  \n",
       "1         소녀시대<|eot_id|>  \n",
       "2        서프라이즈<|eot_id|>  \n",
       "3        유럽 연합<|eot_id|>  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[(utrd[0], utrd[1], trd[1]) for utrd, trd in zip(untrained, trained)],\n",
    "    columns=['정답', '학습전 출력', '학습후 출력']\n",
    ")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
